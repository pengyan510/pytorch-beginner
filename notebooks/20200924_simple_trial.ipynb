{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.shape)\n",
    "display(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c51c2c4fc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return torch.tensor(x).view(-1, 1, 28, 28), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prep, y_train_prep = preprocess(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1, 28, 28]), torch.Size([50000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_prep.size(), y_train_prep.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    TensorDataset(x_train_prep, y_train_prep),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_prep, y_valid_prep = preprocess(x_valid, y_valid)\n",
    "\n",
    "valid_dl = DataLoader(\n",
    "    TensorDataset(x_valid_prep, y_valid_prep),\n",
    "    batch_size=batch_size * 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_test = CNN(1)\n",
    "cnn_test(x_train_prep[:32]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dl, model, loss_func, opt=None):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    cnt_true = 0\n",
    "    for x, y in dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        total_loss += loss * x.size()[0]\n",
    "        total_size += x.size()[0]\n",
    "        cnt_true += torch.sum(torch.argmax(y_pred, dim=1) == y).item()\n",
    "        if opt:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "    return total_loss / total_size, cnt_true / total_size\n",
    "\n",
    "\n",
    "def fit(train_dl, valid_dl, model, loss_func, opt, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, _ = run_epoch(train_dl, model, loss_func, opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss, accuracy = run_epoch(valid_dl, model, loss_func)\n",
    "            \n",
    "        print(f'Epoch {epoch} -  training loss: {train_loss}   validation loss: {valid_loss}   accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(1)\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -  training loss: 0.24849478900432587   validation loss: 0.08025913685560226   accuracy: 0.9782\n",
      "Epoch 1 -  training loss: 0.07405710220336914   validation loss: 0.063135527074337   accuracy: 0.9827\n",
      "Epoch 2 -  training loss: 0.05184417590498924   validation loss: 0.060709770768880844   accuracy: 0.9841\n",
      "Epoch 3 -  training loss: 0.038874633610248566   validation loss: 0.049570079892873764   accuracy: 0.9861\n",
      "Epoch 4 -  training loss: 0.030908148735761642   validation loss: 0.04155666381120682   accuracy: 0.989\n",
      "Epoch 5 -  training loss: 0.025017863139510155   validation loss: 0.050786424428224564   accuracy: 0.987\n",
      "Epoch 6 -  training loss: 0.019913876429200172   validation loss: 0.048358336091041565   accuracy: 0.9881\n",
      "Epoch 7 -  training loss: 0.0161534883081913   validation loss: 0.055755365639925   accuracy: 0.9861\n",
      "Epoch 8 -  training loss: 0.014376461505889893   validation loss: 0.05498270317912102   accuracy: 0.9883\n",
      "Epoch 9 -  training loss: 0.011744600720703602   validation loss: 0.05085475742816925   accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "fit(train_dl, valid_dl, model, loss_func, opt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_dl = DataLoader(\n",
    "    TensorDataset(x_train_prep[:32], y_train_prep[:32]),\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "sample_valid_dl = DataLoader(\n",
    "    TensorDataset(x_valid_prep[:16], y_valid_prep[:16]),\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -  training loss: 0.4473573565483093   validation loss: 0.25837579369544983   accuracy: 0.9375\n",
      "Epoch 1 -  training loss: 0.33440807461738586   validation loss: 0.2840232253074646   accuracy: 0.875\n",
      "Epoch 2 -  training loss: 0.23643618822097778   validation loss: 0.39989110827445984   accuracy: 0.875\n",
      "Epoch 3 -  training loss: 0.21201267838478088   validation loss: 0.4941295385360718   accuracy: 0.8125\n",
      "Epoch 4 -  training loss: 0.19297535717487335   validation loss: 0.4692470133304596   accuracy: 0.8125\n",
      "Epoch 5 -  training loss: 0.14959776401519775   validation loss: 0.35167112946510315   accuracy: 0.9375\n",
      "Epoch 6 -  training loss: 0.12029829621315002   validation loss: 0.24997995793819427   accuracy: 0.9375\n",
      "Epoch 7 -  training loss: 0.0964806079864502   validation loss: 0.19944822788238525   accuracy: 0.9375\n",
      "Epoch 8 -  training loss: 0.0827142596244812   validation loss: 0.18130871653556824   accuracy: 1.0\n",
      "Epoch 9 -  training loss: 0.07398615777492523   validation loss: 0.17651402950286865   accuracy: 1.0\n",
      "Epoch 10 -  training loss: 0.06422670185565948   validation loss: 0.18194246292114258   accuracy: 1.0\n",
      "Epoch 11 -  training loss: 0.055822134017944336   validation loss: 0.19401565194129944   accuracy: 0.9375\n",
      "Epoch 12 -  training loss: 0.04634825885295868   validation loss: 0.21538454294204712   accuracy: 0.9375\n",
      "Epoch 13 -  training loss: 0.04027688503265381   validation loss: 0.24551475048065186   accuracy: 0.9375\n",
      "Epoch 14 -  training loss: 0.036215171217918396   validation loss: 0.27920374274253845   accuracy: 0.875\n",
      "Epoch 15 -  training loss: 0.033066198229789734   validation loss: 0.30916354060173035   accuracy: 0.8125\n",
      "Epoch 16 -  training loss: 0.030406683683395386   validation loss: 0.3267658054828644   accuracy: 0.8125\n",
      "Epoch 17 -  training loss: 0.02759486436843872   validation loss: 0.3325197994709015   accuracy: 0.8125\n",
      "Epoch 18 -  training loss: 0.025259971618652344   validation loss: 0.32764488458633423   accuracy: 0.8125\n",
      "Epoch 19 -  training loss: 0.023166999220848083   validation loss: 0.31743937730789185   accuracy: 0.8125\n",
      "Epoch 20 -  training loss: 0.021185368299484253   validation loss: 0.3052937090396881   accuracy: 0.8125\n",
      "Epoch 21 -  training loss: 0.01957222819328308   validation loss: 0.2923249900341034   accuracy: 0.8125\n",
      "Epoch 22 -  training loss: 0.018226340413093567   validation loss: 0.27995002269744873   accuracy: 0.875\n",
      "Epoch 23 -  training loss: 0.017045393586158752   validation loss: 0.2704913914203644   accuracy: 0.9375\n",
      "Epoch 24 -  training loss: 0.015916720032691956   validation loss: 0.2621488869190216   accuracy: 0.9375\n",
      "Epoch 25 -  training loss: 0.015102863311767578   validation loss: 0.25592100620269775   accuracy: 0.9375\n",
      "Epoch 26 -  training loss: 0.014125749468803406   validation loss: 0.25140514969825745   accuracy: 0.9375\n",
      "Epoch 27 -  training loss: 0.013443008065223694   validation loss: 0.24845874309539795   accuracy: 0.9375\n",
      "Epoch 28 -  training loss: 0.012812241911888123   validation loss: 0.24619346857070923   accuracy: 0.9375\n",
      "Epoch 29 -  training loss: 0.012179657816886902   validation loss: 0.24484381079673767   accuracy: 0.9375\n",
      "Epoch 30 -  training loss: 0.011593550443649292   validation loss: 0.24418872594833374   accuracy: 0.9375\n",
      "Epoch 31 -  training loss: 0.011005833745002747   validation loss: 0.2441316545009613   accuracy: 0.9375\n",
      "Epoch 32 -  training loss: 0.01062650978565216   validation loss: 0.2441924810409546   accuracy: 0.9375\n",
      "Epoch 33 -  training loss: 0.010108709335327148   validation loss: 0.24404862523078918   accuracy: 0.9375\n",
      "Epoch 34 -  training loss: 0.009740486741065979   validation loss: 0.24414408206939697   accuracy: 0.9375\n",
      "Epoch 35 -  training loss: 0.009324073791503906   validation loss: 0.24422743916511536   accuracy: 0.9375\n",
      "Epoch 36 -  training loss: 0.008968129754066467   validation loss: 0.24388739466667175   accuracy: 0.9375\n",
      "Epoch 37 -  training loss: 0.008688241243362427   validation loss: 0.24360427260398865   accuracy: 0.9375\n",
      "Epoch 38 -  training loss: 0.008365526795387268   validation loss: 0.24309641122817993   accuracy: 0.9375\n",
      "Epoch 39 -  training loss: 0.00810292363166809   validation loss: 0.242439866065979   accuracy: 0.9375\n",
      "Epoch 40 -  training loss: 0.00784754753112793   validation loss: 0.24224981665611267   accuracy: 0.9375\n",
      "Epoch 41 -  training loss: 0.007611498236656189   validation loss: 0.2421925663948059   accuracy: 0.9375\n",
      "Epoch 42 -  training loss: 0.00733456015586853   validation loss: 0.24190619587898254   accuracy: 0.9375\n",
      "Epoch 43 -  training loss: 0.007120028138160706   validation loss: 0.24082720279693604   accuracy: 0.9375\n",
      "Epoch 44 -  training loss: 0.006909564137458801   validation loss: 0.24053889513015747   accuracy: 0.9375\n",
      "Epoch 45 -  training loss: 0.006710171699523926   validation loss: 0.2399141490459442   accuracy: 0.9375\n",
      "Epoch 46 -  training loss: 0.006530106067657471   validation loss: 0.23903509974479675   accuracy: 0.9375\n",
      "Epoch 47 -  training loss: 0.006378918886184692   validation loss: 0.23837265372276306   accuracy: 0.9375\n",
      "Epoch 48 -  training loss: 0.00619034469127655   validation loss: 0.23805034160614014   accuracy: 0.9375\n",
      "Epoch 49 -  training loss: 0.0060100555419921875   validation loss: 0.2385323941707611   accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "fit(sample_train_dl, sample_valid_dl, model, loss_func, opt, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
